/*!
  | Find r1 and r2 such that r1+r2*lambda
  | = k, where r1 and r2 or their negations
  | are maximum 128 bits long (see ge_mul_lambda).
  |
  */

crate::ix!();

/**
 | Find r1 and r2 given k, such that 
 | r1 + r2 * lambda == k mod n; 
 |
 | unlike in the full case we don't bother making
 | r1 and r2 be small, we just want them to be
 | nontrivial to get full test coverage for the
 | exhaustive tests. 
 |
 | We therefore (arbitrarily) set 
 | r2 = k + 5 (mod n) and 
 | r1 = k - r2 * lambda (mod n).
 */
#[cfg(EXHAUSTIVE_TEST_ORDER)]
pub fn scalar_split_lambda(
        r1: *mut Scalar,
        r2: *mut Scalar,
        k:  *const Scalar)  {
    
    todo!();
        /*
            *r2 = (*k + 5) % EXHAUSTIVE_TEST_ORDER;
        *r1 = (*k + (EXHAUSTIVE_TEST_ORDER - *r2) * EXHAUSTIVE_TEST_LAMBDA) % EXHAUSTIVE_TEST_ORDER;
        */
}

/**
 | Both lambda and beta are primitive cube roots
 | of unity.  
 |
 | That is lamba^3 == 1 mod n and beta^3 == 1 mod
 | p, where n is the curve order and p is the
 | field order.
 |
 | Futhermore, because (X^3 - 1) = (X - 1)(X^2
 | + X + 1), the primitive cube roots of unity are
 | roots of X^2 + X + 1.  
 |
 | Therefore lambda^2 + lamba == -1 mod n and
 | beta^2 + beta == -1 mod p.
 |
 | (The other primitive cube roots of unity are
 | lambda^2 and beta^2 respectively.)
 |
 | Let l = -1/2 + i*sqrt(3)/2, 
 | the complex root of X^2 + X + 1. 
 |
 | We can define a ring homomorphism phi : Z[l] ->
 | Z_n where phi(a + b*l) == a + b*lambda mod n. 
 |
 | The kernel of phi is a lattice over Z[l]
 | (considering Z[l] as a Z-module). 
 |
 | This lattice is generated by a reduced basis
 | {a1 + b1*l, a2 + b2*l} where
 |
 | - a1 =      {0x30,0x86,0xd2,0x21,0xa7,0xd4,0x6b,0xcd,0xe8,0x6c,0x90,0xe4,0x92,0x84,0xeb,0x15}
 | - b1 =     -{0xe4,0x43,0x7e,0xd6,0x01,0x0e,0x88,0x28,0x6f,0x54,0x7f,0xa9,0x0a,0xbf,0xe4,0xc3}
 | - a2 = {0x01,0x14,0xca,0x50,0xf7,0xa8,0xe2,0xf3,0xf6,0x57,0xc1,0x10,0x8d,0x9d,0x44,0xcf,0xd8}
 | - b2 =      {0x30,0x86,0xd2,0x21,0xa7,0xd4,0x6b,0xcd,0xe8,0x6c,0x90,0xe4,0x92,0x84,0xeb,0x15}
 |
 | "Guide to Elliptic Curve Cryptography"
 | (Hankerson, Menezes, Vanstone) gives an
 | algorithm (algorithm 3.74) to find k1 and k2
 | given k, such that k1 + k2 * lambda == k mod n,
 | and k1 and k2 are small in absolute value.
 |
 | The algorithm computes 
 | c1 = round(b2 * k / n) and 
 | c2 = round((-b1) * k / n), and gives
 | k1 = k - (c1*a1 + c2*a2) and 
 | k2 = -(c1*b1 + c2*b2). 
 |
 | Instead, we use modular arithmetic, and compute 
 | r2 = k2 mod n, and 
 | r1 = k1 mod n = (k - r2 * lambda) mod n, 
 | avoiding the need for the constants a1 and a2.
 |
 | g1, g2 are precomputed constants used to
 | replace division with a rounded multiplication
 | when decomposing the scalar for an
 | endomorphism-based point multiplication.
 |
 | The possibility of using precomputed estimates
 | is mentioned in "Guide to Elliptic Curve
 | Cryptography" (Hankerson, Menezes, Vanstone) in
 | section 3.5.
 |
 | The derivation is described in the paper
 | "Efficient Software Implementation of
 | Public-Key Cryptography on Sensor Networks
 | Using the MSP430X Microcontroller" (Gouvea,
 | Oliveira, Lopez), Section 4.3 (here we use
 | a somewhat higher-precision estimate):
 |
 | d = a1*b2 - b1*a2
 | g1 = round(2^384 * b2/d)
 | g2 = round(2^384 * (-b1)/d)
 |
 | (Note that d is also equal to the curve order,
 | n, here because [a1,b1] and [a2,b2] can be
 | found as outputs of the Extended Euclidean
 | Algorithm on inputs n and lambda).
 |
 | The function below splits k into r1 and r2, such that
 |
 | - r1 + lambda * r2 == k (mod n)
 | - either r1 < 2^128 or -r1 mod n < 2^128
 | - either r2 < 2^128 or -r2 mod n < 2^128
 |
 | See proof below.
 */
#[cfg(not(EXHAUSTIVE_TEST_ORDER))]
pub fn scalar_split_lambda(
        r1: *mut Scalar,
        r2: *mut Scalar,
        k:  *const Scalar)  {
    
    todo!();
        /*
            scalar c1, c2;
        static const scalar minus_b1 = SCALAR_CONST(
            0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,
            0xE4437ED6UL, 0x010E8828UL, 0x6F547FA9UL, 0x0ABFE4C3UL
        );
        static const scalar minus_b2 = SCALAR_CONST(
            0xFFFFFFFFUL, 0xFFFFFFFFUL, 0xFFFFFFFFUL, 0xFFFFFFFEUL,
            0x8A280AC5UL, 0x0774346DUL, 0xD765CDA8UL, 0x3DB1562CUL
        );
        static const scalar g1 = SCALAR_CONST(
            0x3086D221UL, 0xA7D46BCDUL, 0xE86C90E4UL, 0x9284EB15UL,
            0x3DAA8A14UL, 0x71E8CA7FUL, 0xE893209AUL, 0x45DBB031UL
        );
        static const scalar g2 = SCALAR_CONST(
            0xE4437ED6UL, 0x010E8828UL, 0x6F547FA9UL, 0x0ABFE4C4UL,
            0x221208ACUL, 0x9DF506C6UL, 0x1571B4AEUL, 0x8AC47F71UL
        );
        VERIFY_CHECK(r1 != k);
        VERIFY_CHECK(r2 != k);
        /* these _var calls are constant time since the shift amount is constant */
        scalar_mul_shift_var(&c1, k, &g1, 384);
        scalar_mul_shift_var(&c2, k, &g2, 384);
        scalar_mul(&c1, &c1, &minus_b1);
        scalar_mul(&c2, &c2, &minus_b2);
        scalar_add(r2, &c1, &c2);
        scalar_mul(r1, r2, &const_lambda);
        scalar_negate(r1, r1);
        scalar_add(r1, r1, k);

    #ifdef VERIFY
        scalar_split_lambda_verify(r1, r2, k);
    #endif
        */
}

